[[advanced.topics.optimizing.scalability]]
= Optimization and Scalability

include::entities.adoc[]

[[optimizing.apache-tomcat]]
== Optimizing Apache and Tomcat


[WARNING]
.Altering Apache and Tomcat Parameters
====
Apache and Tomcat Parameters should only be modified with support or consulting as these parameters can have severe and catastrophic performance impacts on your server when improperly adjusted.
SUSE will not be able to provide support for catastrophic failure when these advanced parameters are modified without consultation.
Tuning values for Apache httpd and Tomcat requires that you align these parameters with your server hardware.
Furthermore testing of these altered values should be performed within a test environment.
====



[[at.apache.httpd.maxclient.parameter]]
=== Apache's httpd MaxClients Parameter

The [parameter]``MaxClients`` setting determines the number of Apache httpd processes, and thus limits the number of client connections that can be made at the same time (SUSE Manager uses the pre-fork MultiProcessing Modules).
The default value for [parameter]``MaxClients`` in SUSE Manager is 150.
If you need to set the [parameter]``MaxClients`` value greater than 150, Apache httpd's ServerLimit setting and Tomcat's [parameter]``maxThreads`` must also be increased accordingly (see below).

[WARNING]
====
The Apache httpd [parameter]``MaxClients`` parameter must always be less or equal than Tomcat's [parameter]``maxThreads`` parameter!
====

If the [parameter]``MaxClients`` value is reached while the software is running, new client connections will be queued and forced to wait, this may result in timeouts.
You can check the Apache httpd's [path]``error.log`` for details:

----
[error] Server reached MaxClients setting, consider increasing the MaxClients setting
----

The default [parameter]``MaxClients`` parameter can be overridden on SUSE Manager by editing the [path]``server-tuning.conf`` file located at [systemitem]``/etc/apache2/``.
For example [path]``server-tuning.conf`` file:

----
# prefork MPM
   <IfModule prefork.c>
           # number of server processes to start
           # http://httpd.apache.org/docs/2.2/mod/mpm_common.html#startservers
           StartServers         5
           # minimum number of server processes which are kept spare
           # http://httpd.apache.org/docs/2.2/mod/prefork.html#minspareservers
           MinSpareServers      5
           # maximum number of server processes which are kept spare
           # http://httpd.apache.org/docs/2.2/mod/prefork.html#maxspareservers
           MaxSpareServers     10
           # highest possible MaxClients setting for the lifetime of the Apache process.
           # http://httpd.apache.org/docs/2.2/mod/mpm_common.html#serverlimit
           ServerLimit        150
           # maximum number of server processes allowed to start
           # http://httpd.apache.org/docs/2.2/mod/mpm_common.html#maxclients
           MaxClients         150
           # maximum number of requests a server process serves
           # http://httpd.apache.org/docs/2.2/mod/mpm_common.html#maxrequestsperchild
           MaxRequestsPerChild  10000
   </IfModule>
----




[[at.tomcat.maxthreads.parameter]]
=== Tomcat's maxThreads Parameter

Tomcat's [parameter]``maxThreads`` represents the maximum number of request processing threads that it will create.
This value determines the maximum number of simultaneous requests that it is able to handle.
All HTTP requests to the SUSE Manager server (from clients, browsers, XMLRPC API scripts, etc.) are handled by Apache httpd, and some of them are routed to Tomcat for further processing.
It is thus important that Tomcat is able to serve the same amount of simultaneous requests that Apache httpd is able to serve in the worst case.
The default value for SUSE Manager is 200 and should always be equal or greater than Apache httpd's [parameter]``MaxClients``.
The [parameter]``maxThreads`` value is located within the [path]``server.xml`` file located at [systemitem]``/etc/tomcat/``.

Example relevant lines in [path]``server.xml``:

----
<Connector port="8009" protocol="AJP/1.3" redirectPort="8443" URIEncoding="UTF-8" address="127.0.0.1" maxThreads="200" connectionTimeout="20000"/>
<Connector port="8009" protocol="AJP/1.3" redirectPort="8443" URIEncoding="UTF-8" address="::1" maxThreads="200" connectionTimeout="20000"/>
----

[NOTE]
.Tuning Notes
====
When configuring Apache httpd's [parameter]``MaxClients`` and Tomcat's [parameter]``maxThreads`` parameters you should also take into consideration that each HTTP connection will need one or more database connections.
If the RDBMS is not able to serve an adequate amount of connections, issues will arise.
See the following equation for a rough calculation of the needed amount of database connections:

----
((3 * java_max) +  apache_max + 60)
----

Where:

* 3 is the number of Java processes the server runs with pooled connections (Tomcat, Taskomatic and Search)
* java_max is the maximum number of connections per Java pool (20 by default, changeable in [path]``/etc/rhn/rhn.conf`` via the hibernate.c3p0.max_size parameter)
* apache_max is Apache httpd's [parameter]``MaxClients``
* 60 is the maximum expected number of extra connections for local processes and other uses
====




[[optimizing.big]]
== Big Scale Deployment (1000 Minions or More)

In the following sections find considerations about a big scale deployment.
In this context, a big scale compromises 1000 minions or more.



[[optimizing.big.general]]
=== General Recommendations

{suse} recommends the following in a big scale {productname} deployment:

* {productname} servers should have at least 8 recent {x86} cores, 32 GiB of RAM, and, most important, fast I/O devices such as at least an SSD (2 SSDs in RAID-0 are strongly recommended).
* Proxies with many minions (hundreds) should have at least 2 recent {x86} cores and 16 GiB of RAM.
* Use one {susemgrproxy} per 500-1000 clients.
Keep into account that download time depends on network capacity.
Here is a rough example calculation with physical link speed of 1 GB/s:
+

----
400 Megabytes  *        3000       /      119 Megabyte/s        / 60
= 169 Minutes
----
+

This is:
+

----
Size of updates * Number of minions / Theoretical download speed / 60
----

* Depending on hardware you can accept hundreds of minion keys.
* Plan time for onboarding minions{mdash} at least one hour per 1000 minions.
* It is not recommended onboarding more than approx.
1000 minions directly to the {productname} server{mdash} proxies should be used instead.
This is because every minion can use up to 3 TCP connections simultaneously, and too many TCP connections can cause performance issues.
* If the following error appears in output of [command]``dmesg``, you probably have an excessive number of minions attached to a single {productname} server or proxy for the ARP cache to contain all of their addresses:
+

----
kernel: neighbour table overflow
----
+

In that case, increase the ARP cache values via [systemitem]``sysctl``, for example, by adding the following lines to [path]``/etc/sysctl.conf``:
+

----
net.ipv4.neigh.default.gc_thresh1 = 4096
net.ipv4.neigh.default.gc_thresh2 = 8192
net.ipv4.neigh.default.gc_thresh3 = 16384
net.ipv4.neigh.default.gc_interval = 60
net.ipv4.neigh.default.gc_stale_time = 120
----

[TIP]
.Start Small and Scale Up
====
Always start small and scale up gradually.
Keep the server monitored in order to identify possible issues early.
====

[[optimizing.big.tuning]]
=== Tuning Proposals

{suse} proposes the following tuning settings in a big scale {productname} deployment:

* Increase the maximum Tomcat heap memory to face a potentially long queue of Salt return results. Set 8 GiB instead of the current default 1 GiB: parameter [parameter]``Xmx1G`` in [path]``/etc/sysconfig/tomcat`` (affects onboarding and Action execution).
* Increase the number of Taskomatic workers, allowing to parallelize work on a high number of separate jobs. Set parameter [parameter]``org.quartz.threadPool.threadCount = 100`` in [path]``/etc/rhn/rhn.conf`` (affects onboarding and staging).
* Allow Taskomatic to check for runnable jobs more frequently to reduce latency. Set parameter [parameter]``org.quartz.scheduler.idleWaitTime = 1000`` in [path]``/etc/rhn/rhn.conf`` (affects onboarding, staging and Action execution).
* Increase Tomcat's Salt return result workers to allow parallelizing work on a high number of Salt return results. Set parameter [parameter]``java.message_queue_thread_pool_size = 100`` in [path]``/etc/rhn/rhn.conf`` (affects patching).
* Increase the number of PostgreSQL connections available to Java applications (Tomcat, Taskomatic) according to the previous parameters, otherwise extra workers will starve waiting for a connection. Set parameter [parameter]``hibernate.c3p0.max_size = 150`` in [path]``/etc/rhn/rhn.conf`` (affects all minion operations). Make sure enough PostgreSQL connections are configured before changing this parameter {mdash} refer to ``smdba system-check autotuning --help`` to get automatic tuning of the PostgreSQL configuration file while changing the number of available connections. Additional manual tuning is usually not necessary but might be required depending on scale and exact use cases.
* Increase the number of Taskomatic's ``minion-action-executor`` worker threads allowing to parallelize the scheduling of Actions to minions. Set parameter [parameter]``taskomatic.com.redhat.rhn.taskomatic.task.MinionActionExecutor.parallel_threads = 8`` in [path]``/etc/rhn/rhn.conf`` (affects all minion operations, especially staging).
* Increase Salt's presence ping timeouts if responses might come back later than the defaults. Set parameters [parameter]``java.salt_presence_ping_timeout = 20`` and [parameter]``java.salt_presence_ping_gather_job_timeout = 20`` in [path]``/etc/rhn/rhn.conf`` (affects all minion operations).
* Increase the Salt master worker threads allowing to parallelize more requests (otherwise Tomcat and Taskomatic workers will starve waiting for the Salt API). Set parameter [parameter]``worker_threads: 100`` in [path]``/etc/salt/master.d/susemanager.conf`` (affects onboarding and patching).
* Disable daily comparison of configuration files. Click on menu:Admin[Task Schedules], then on the btn:[compare-configs-default] link, then on the btn:[Disable Schedule] button and finally on btn:[Delete Schedule].

Note that increasing the number of Postgres connections and Salt workers will require more RAM, make sure the {productname} server is monitored and swap is never used.

Also note the above settings should be regarded as guidelines{mdash}they have been tested to be safe but care should be exercised when changing them, and consulting support is highly recommended.
